{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gunasekaran81m/melanies_smoothies/blob/main/Mcq_lc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain langchain-community faiss-cpu pypdf python-dotenv sentence-transformers"
      ],
      "metadata": {
        "id": "PtVcUOo5t-Vc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "810617c3-7b84-42a9-825c-2021963c3d2d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.3.31)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (6.2.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.79)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.40)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.44)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.11.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "import torch\n",
        "from typing import List, Dict\n",
        "import json"
      ],
      "metadata": {
        "id": "P0jdXMO8vR6e"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MCQGenerator:\n",
        "    def __init__(self, model_name=\"microsoft/DialoGPT-medium\", embedding_model=\"sentence-transformers/all-mpnet-base-v2\"):\n",
        "        \"\"\"\n",
        "        Initialize the MCQ Generator\n",
        "\n",
        "        Args:\n",
        "            model_name: HuggingFace model for question generation\n",
        "            embedding_model: Model for text embeddings\n",
        "        \"\"\"\n",
        "        self.model_name = model_name\n",
        "        self.embedding_model = embedding_model\n",
        "        self.vector_store = None\n",
        "        self.llm = None\n",
        "        self.setup_llm()\n",
        "\n",
        "    def setup_llm(self):\n",
        "        \"\"\"Initialize the language model\"\"\"\n",
        "        try:\n",
        "            tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "            model = AutoModelForCausalLM.from_pretrained(\n",
        "                self.model_name,\n",
        "                torch_dtype=torch.float16,\n",
        "                device_map=\"auto\",\n",
        "                low_cpu_mem_usage=True\n",
        "            )\n",
        "\n",
        "            pipe = pipeline(\n",
        "                \"text-generation\",\n",
        "                model=model,\n",
        "                tokenizer=tokenizer,\n",
        "                max_length=1024,\n",
        "                temperature=0.7,\n",
        "                top_p=0.95,\n",
        "                repetition_penalty=1.15\n",
        "            )\n",
        "\n",
        "            self.llm = HuggingFacePipeline(pipeline=pipe)\n",
        "            print(f\"LLM {self.model_name} loaded successfully!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading LLM: {e}\")\n",
        "            # Fallback to a smaller model\n",
        "            self.setup_fallback_llm()\n",
        "\n",
        "    def setup_fallback_llm(self):\n",
        "        \"\"\"Fallback to a smaller model if primary fails\"\"\"\n",
        "        try:\n",
        "            self.llm = HuggingFacePipeline.from_model_id(\n",
        "                model_id=\"gpt2\",\n",
        "                task=\"text-generation\",\n",
        "                pipeline_kwargs={\"max_length\": 512}\n",
        "            )\n",
        "            print(\"Fallback LLM (GPT-2) loaded successfully!\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading fallback LLM: {e}\")\n",
        "\n",
        "    def load_pdf(self, pdf_path: str):\n",
        "        \"\"\"Load and process PDF file\"\"\"\n",
        "        try:\n",
        "            loader = PyPDFLoader(pdf_path)\n",
        "            documents = loader.load()\n",
        "\n",
        "            # Split documents into chunks\n",
        "            text_splitter = RecursiveCharacterTextSplitter(\n",
        "                chunk_size=1000,\n",
        "                chunk_overlap=200,\n",
        "                length_function=len\n",
        "            )\n",
        "\n",
        "            chunks = text_splitter.split_documents(documents)\n",
        "            print(f\"Loaded {len(chunks)} chunks from PDF\")\n",
        "\n",
        "            return chunks\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading PDF: {e}\")\n",
        "            return []\n",
        "\n",
        "    def create_vector_store(self, documents):\n",
        "        \"\"\"Create FAISS vector store from documents\"\"\"\n",
        "        try:\n",
        "            embeddings = HuggingFaceEmbeddings(\n",
        "                model_name=self.embedding_model,\n",
        "                model_kwargs={'device': 'cpu'}\n",
        "            )\n",
        "\n",
        "            self.vector_store = FAISS.from_documents(documents, embeddings)\n",
        "            print(\"Vector store created successfully!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error creating vector store: {e}\")\n",
        "\n",
        "    def search_relevant_content(self, query: str, k: int = 3):\n",
        "        \"\"\"Search for relevant content in the vector store\"\"\"\n",
        "        if self.vector_store is None:\n",
        "            return \"No vector store available. Please load a PDF first.\"\n",
        "\n",
        "        try:\n",
        "            docs = self.vector_store.similarity_search(query, k=k)\n",
        "            return \"\\n\\n\".join([doc.page_content for doc in docs])\n",
        "        except Exception as e:\n",
        "            print(f\"Error searching content: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "    def generate_mcqs(self, topic: str, num_questions: int = 5, difficulty: str = \"medium\"):\n",
        "        \"\"\"Generate MCQs based on the topic\"\"\"\n",
        "\n",
        "        # Search for relevant content\n",
        "        relevant_content = self.search_relevant_content(topic)\n",
        "\n",
        "        if not relevant_content:\n",
        "            return {\"error\": \"No relevant content found for the topic\"}\n",
        "\n",
        "        # Prompt template for MCQ generation\n",
        "        prompt_template = PromptTemplate(\n",
        "            input_variables=[\"content\", \"topic\", \"num_questions\", \"difficulty\"],\n",
        "            template=\"\"\"\n",
        "            Based on the following content, generate {num_questions} multiple-choice questions about {topic} with {difficulty} difficulty.\n",
        "\n",
        "            Content:\n",
        "            {content}\n",
        "\n",
        "            Generate the questions in JSON format with the following structure:\n",
        "            {{\n",
        "                \"mcqs\": [\n",
        "                    {{\n",
        "                        \"question\": \"question text\",\n",
        "                        \"options\": {{\n",
        "                            \"A\": \"option A\",\n",
        "                            \"B\": \"option B\",\n",
        "                            \"C\": \"option C\",\n",
        "                            \"D\": \"option D\"\n",
        "                        }},\n",
        "                        \"correct_answer\": \"A\",\n",
        "                        \"explanation\": \"brief explanation\"\n",
        "                    }}\n",
        "                ]\n",
        "            }}\n",
        "\n",
        "            Ensure questions are clear, options are plausible, and only one correct answer.\n",
        "            Return only the JSON, no additional text.\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "        # Create LLM chain\n",
        "        mcq_chain = LLMChain(llm=self.llm, prompt=prompt_template)\n",
        "\n",
        "        try:\n",
        "            response = mcq_chain.run({\n",
        "                \"content\": relevant_content,\n",
        "                \"topic\": topic,\n",
        "                \"num_questions\": num_questions,\n",
        "                \"difficulty\": difficulty\n",
        "            })\n",
        "\n",
        "            # Clean the response and parse JSON\n",
        "            response = response.strip()\n",
        "            if response.startswith(\"```json\"):\n",
        "                response = response[7:]\n",
        "            if response.endswith(\"```\"):\n",
        "                response = response[:-3]\n",
        "\n",
        "            mcq_data = json.loads(response)\n",
        "            return mcq_data\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating MCQs: {e}\")\n",
        "            return {\"error\": f\"Failed to generate MCQs: {str(e)}\"}\n",
        "\n",
        "    def process_pdf_and_generate_mcqs(self, pdf_path: str, topic: str, num_questions: int = 5):\n",
        "        \"\"\"Complete pipeline: Load PDF and generate MCQs\"\"\"\n",
        "        print(\"Loading PDF...\")\n",
        "        documents = self.load_pdf(pdf_path)\n",
        "\n",
        "        if not documents:\n",
        "            return {\"error\": \"Failed to load PDF\"}\n",
        "\n",
        "        print(\"Creating vector store...\")\n",
        "        self.create_vector_store(documents)\n",
        "\n",
        "        print(f\"Generating {num_questions} MCQs about {topic}...\")\n",
        "        return self.generate_mcqs(topic, num_questions)"
      ],
      "metadata": {
        "id": "mA_792Lwvwcp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuehcHc4ZdSW",
        "outputId": "dd4be81b-d4e8-45a4-9946-56694310d3a3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/pdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huzKXAhBUvZT",
        "outputId": "40884a03-9500-4ec3-de97-edefbf8103d9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLYUAyILUvN5",
        "outputId": "ab68de52-a7ae-4c50-eebe-595c999092e9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cbse.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Initialize the MCQ generator\n",
        "    mcq_gen = MCQGenerator()\n",
        "\n",
        "    # Path to your PDF file\n",
        "    pdf_path = \"cbse.pdf\"  # Replace with your PDF path\n",
        "\n",
        "    # Topic for which you want to generate MCQs\n",
        "    topic = \"machine learning fundamentals\"\n",
        "\n",
        "    # Generate MCQs\n",
        "    result = mcq_gen.process_pdf_and_generate_mcqs(\n",
        "        pdf_path=pdf_path,\n",
        "        topic=topic,\n",
        "        num_questions=3\n",
        "    )\n",
        "\n",
        "    # Display results\n",
        "    if \"mcqs\" in result:\n",
        "        print(f\"\\nGenerated {len(result['mcqs'])} MCQs about '{topic}':\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        for i, mcq in enumerate(result[\"mcqs\"], 1):\n",
        "            print(f\"\\n{i}. {mcq['question']}\")\n",
        "            for option, text in mcq['options'].items():\n",
        "                print(f\"   {option}) {text}\")\n",
        "            print(f\"   Correct: {mcq['correct_answer']}\")\n",
        "            print(f\"   Explanation: {mcq['explanation']}\")\n",
        "    else:\n",
        "        print(f\"Error: {result.get('error', 'Unknown error')}\")\n",
        "\n",
        "# Simple function for quick testing\n",
        "def quick_test():\n",
        "    \"\"\"Quick test with a sample PDF\"\"\"\n",
        "    generator = MCQGenerator()\n",
        "\n",
        "    # You can use any PDF file path\n",
        "    try:\n",
        "        result = generator.process_pdf_and_generate_mcqs(\n",
        "            pdf_path=\"your_document.pdf\",\n",
        "            topic=\"artificial intelligence\",\n",
        "            num_questions=2\n",
        "        )\n",
        "        print(json.dumps(result, indent=2))\n",
        "    except Exception as e:\n",
        "        print(f\"Test failed: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "GwVy9S8IuGSR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca961f86-ae2e-4a89-f186-018369268466"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Device set to use cpu\n",
            "/tmp/ipython-input-4138366118.py:37: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
            "  self.llm = HuggingFacePipeline(pipeline=pipe)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 20 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 22 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 24 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 25 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 26 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 28 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 29 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 30 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 31 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 32 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 33 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 34 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 35 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 36 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 37 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 38 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 39 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 40 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 42 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 43 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 44 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 45 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 46 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 47 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 48 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 49 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 50 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 51 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 52 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 53 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 54 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 55 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 56 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 57 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 58 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 59 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 60 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 61 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 62 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 63 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 64 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 65 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 66 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 67 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 68 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 69 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 70 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 72 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 73 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 74 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 75 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 76 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 77 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 78 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 79 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 80 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 81 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 82 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 83 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 84 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 85 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 86 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 87 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 88 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 89 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 90 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 91 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 92 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 93 0 (offset 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM microsoft/DialoGPT-medium loaded successfully!\n",
            "Loading PDF...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pypdf._reader:Ignoring wrong pointing object 94 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 95 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 96 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 97 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 98 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 99 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 100 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 101 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 102 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 104 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 105 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 106 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 107 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 108 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 109 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 110 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 111 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 112 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 113 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 114 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 115 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 116 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 117 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 118 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 119 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 120 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 121 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 122 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 123 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 124 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 125 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 126 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 127 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 128 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 129 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 130 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 131 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 132 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 133 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 134 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 135 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 136 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 137 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 138 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 139 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 140 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 141 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 143 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 144 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 145 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 146 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 147 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 148 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 149 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 150 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 151 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 152 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 153 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 154 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 155 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 156 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 158 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 159 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 160 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 161 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 162 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 163 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 165 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 166 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 167 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 168 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 169 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 170 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 171 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 172 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 173 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 174 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 176 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 177 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 178 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 179 0 (offset 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 6 chunks from PDF\n",
            "Creating vector store...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4138366118.py:82: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embeddings = HuggingFaceEmbeddings(\n",
            "/tmp/ipython-input-4138366118.py:146: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  mcq_chain = LLMChain(llm=self.llm, prompt=prompt_template)\n",
            "/tmp/ipython-input-4138366118.py:149: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = mcq_chain.run({\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1253 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector store created successfully!\n",
            "Generating 3 MCQs about machine learning fundamentals...\n",
            "Error generating MCQs: Input length of input_ids is 1253, but `max_length` is set to 1024. This can lead to unexpected behavior. You should consider increasing `max_length` or, better yet, setting `max_new_tokens`.\n",
            "Error: Failed to generate MCQs: Input length of input_ids is 1253, but `max_length` is set to 1024. This can lead to unexpected behavior. You should consider increasing `max_length` or, better yet, setting `max_new_tokens`.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}